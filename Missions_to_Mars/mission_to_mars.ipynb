{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mission to Mars\n",
    "\n",
    "Build a web application that scrapes various websites for data related to the Mission to Mars and displays the information in a single HTML page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pymongo\n",
    "import time\n",
    "from splinter import Browser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete your initial scraping using Jupyter Notebook, BeautifulSoup, Pandas, and Requests/Splinter.\n",
    "\n",
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "\n",
    "# Define database and collection\n",
    "db = client.mars_db\n",
    "collection = db.marsData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA Mars News\n",
    "\n",
    "Scrape the NASA Mars News Site and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of page to be scraped\n",
    "#found odd html from given url = 'https://mars.nasa.gov/news/'\n",
    "#switched to search results landing for Mars Nasa News\n",
    "news_url = 'https://mars.nasa.gov/mars2020/news/'\n",
    "\n",
    "# Retrieve page with the requests module\n",
    "news_response = requests.get(news_url)\n",
    "# Create BeautifulSoup object; parse with 'html'\n",
    "news_soup = bs(news_response.text, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA, ULA Launch Mars 2020 Perseverance Rover Mission to Red Planet\n",
      "The agency's Mars 2020 mission is on its way. It will land at Jezero Crater in about seven months, on Feb. 18, 2021.\n"
     ]
    }
   ],
   "source": [
    "# Scrape the latest News Title and Paragraph Text\n",
    "news_title = news_soup.find(\"div\", class_='listTextLabel').find('h2', class_='alt01').text.strip()\n",
    "news_p = news_soup.find(\"div\", class_='listTextLabel').find('p').text.strip()\n",
    "print(news_title)\n",
    "print(news_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image\n",
    "\n",
    "Visit the url for JPL Featured Space Image.\n",
    "\n",
    "Use splinter to navigate the site and find the image url for the current Featured Mars Image and assign the url string to a variable called featured_image_url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splinter browser setup for MacOS\n",
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JPL Mars Space Images URL\n",
    "img_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "#browse to page\n",
    "browser.visit(img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the first full size image\n",
    "img_html = browser.html\n",
    "img_soup = bs(img_html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA08003-1920x1200.jpg\n"
     ]
    }
   ],
   "source": [
    "#featured image is in the carousel item class, style section; parse by single quote and take second element for url\n",
    "imgs = img_soup.find(class_ = \"carousel_item\")['style']\n",
    "featured_image = imgs.split(\"'\")[1]\n",
    "#add the domain as the base to get the full URL\n",
    "img_base_url = 'https://www.jpl.nasa.gov'\n",
    "featured_image_url = img_base_url + featured_image\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts\n",
    "\n",
    "Visit the Mars Facts webpage and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the url and use pandas to pull table\n",
    "facts_url = 'https://space-facts.com/mars/'\n",
    "facts_url_tables = pd.read_html(facts_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull the first table on the page into a data frame\n",
    "mars_facts_df = facts_url_tables[0]\n",
    "mars_facts_df.columns = ['Label', 'Value']\n",
    "mars_facts_df.set_index('Label', inplace=True)\n",
    "#mars_facts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equatorial Diameter:</th>\n",
       "      <td>6,792 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polar Diameter:</th>\n",
       "      <td>6,752 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mass:</th>\n",
       "      <td>6.39 × 10^23 kg (0.11 Earths)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moons:</th>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbit Distance:</th>\n",
       "      <td>227,943,824 km (1.38 AU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbit Period:</th>\n",
       "      <td>687 days (1.9 years)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surface Temperature:</th>\n",
       "      <td>-87 to -5 °C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Record:</th>\n",
       "      <td>2nd millennium BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recorded By:</th>\n",
       "      <td>Egyptian astronomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use pandas to convert the table to a HTML table string\n",
    "html_table = mars_facts_df.to_html()\n",
    "from IPython.display import HTML\n",
    "display(HTML(html_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres\n",
    "\n",
    "Visit the USGS Astrogeology site to obtain high resolution images for each of Mars' hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splinter browser setup for MacOS\n",
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "#set the URL and request\n",
    "hemi_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "# hemi_response = requests.get(hemi_url)\n",
    "browser.visit(hemi_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse the landing page, isolate the image links in the item div\n",
    "hemi_html = browser.html\n",
    "hemi_soup = bs(hemi_html, \"html.parser\")\n",
    "hemi_links = hemi_soup.find_all(\"div\", class_ = \"item\")\n",
    "\n",
    "#create a list for the names and image links\n",
    "hemi_img_urls = []\n",
    "\n",
    "#loop thru each link and grab the name and full size image\n",
    "for link in hemi_links:\n",
    "    #dictionary to hold the name/link pairs\n",
    "    hemi_dict = {}\n",
    "    #name is in the h3 text\n",
    "    img_name = link.find(\"h3\").text\n",
    "    #link is in each desctiption, a href\n",
    "    img_link = link.find(\"div\", class_ = \"description\").a[\"href\"]\n",
    "    #add the base url\n",
    "    link_base = \"https://astrogeology.usgs.gov\"\n",
    "    visit_link = link_base + img_link\n",
    "    \n",
    "    #visit the link\n",
    "    browser.visit(visit_link)\n",
    "    #don't go too fast\n",
    "    time.sleep(5)\n",
    "    \n",
    "    #parse the html\n",
    "    indv_hemi_html = browser.html\n",
    "    indv_hemi_soup = bs(indv_hemi_html, 'html.parser')\n",
    "    \n",
    "    #grab the full image link from wide-image src\n",
    "    indv_hemi_url = indv_hemi_soup.find(\"img\", class_ = \"wide-image\")[\"src\"]\n",
    "    \n",
    "    #add to dictionary as hemi_img_name, hemi_img_url\n",
    "    hemi_dict['hemi_img_name'] = img_name\n",
    "    hemi_dict['hemi_img_url'] = link_base + indv_hemi_url\n",
    "    #put dictionary into hemi_img_urls\n",
    "    hemi_img_urls.append(hemi_dict)\n",
    "    browser.back()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"hemi_img_name\": \"Cerberus Hemisphere Enhanced\",\n",
      "    \"hemi_img_url\": \"https://astrogeology.usgs.gov/cache/images/f5e372a36edfa389625da6d0cc25d905_cerberus_enhanced.tif_full.jpg\"\n",
      "  },\n",
      "  {\n",
      "    \"hemi_img_name\": \"Schiaparelli Hemisphere Enhanced\",\n",
      "    \"hemi_img_url\": \"https://astrogeology.usgs.gov/cache/images/3778f7b43bbbc89d6e3cfabb3613ba93_schiaparelli_enhanced.tif_full.jpg\"\n",
      "  },\n",
      "  {\n",
      "    \"hemi_img_name\": \"Syrtis Major Hemisphere Enhanced\",\n",
      "    \"hemi_img_url\": \"https://astrogeology.usgs.gov/cache/images/555e6403a6ddd7ba16ddb0e471cadcf7_syrtis_major_enhanced.tif_full.jpg\"\n",
      "  },\n",
      "  {\n",
      "    \"hemi_img_name\": \"Valles Marineris Hemisphere Enhanced\",\n",
      "    \"hemi_img_url\": \"https://astrogeology.usgs.gov/cache/images/b3c7c6c9138f57b4756be9b9c43e3a48_valles_marineris_enhanced.tif_full.jpg\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(hemi_img_urls, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
